{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":150545,"sourceType":"datasetVersion","datasetId":70909}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pickle\nimport cv2\nfrom os import listdir\nfrom sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer\nfrom keras.models import Sequential\nfrom keras.layers import BatchNormalization, Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Flatten, Dropout, Dense\nfrom keras import backend as K\nfrom tensorflow.keras.utils import img_to_array\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, classification_report\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-10T23:47:15.953604Z","iopub.execute_input":"2024-12-10T23:47:15.953906Z","iopub.status.idle":"2024-12-10T23:47:28.886061Z","shell.execute_reply.started":"2024-12-10T23:47:15.953872Z","shell.execute_reply":"2024-12-10T23:47:28.885309Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"EPOCHS = 40\nINIT_LR = 1e-3\nBS = 32\ndefault_image_size = tuple((256, 256))\nimage_size = 0\ndirectory_root = '/kaggle/input/plantdisease'\nwidth=256\nheight=256\ndepth=3\n\ndef convertImageToArray(image_dir):\n    try:\n        image = cv2.imread(image_dir)\n        if image is not None :\n            image = cv2.resize(image, default_image_size)   \n            return img_to_array(image)\n        else :\n            return np.array([])\n    except Exception as e:\n        print(f\"Error : {e}\")\n        return None\n\nimage_list, label_list = [], []\ntry:\n    print(\"[INFO] Loading images ...\")\n    root_dir = listdir(directory_root)\n    for directory in root_dir :\n        # remove .DS_Store from list\n        if directory == \".DS_Store\" :\n            root_dir.remove(directory)\n\n    for plant_folder in root_dir :\n        plant_disease_folder_list = listdir(f\"{directory_root}/{plant_folder}\")\n        \n        for disease_folder in plant_disease_folder_list :\n            # remove .DS_Store from list\n            if disease_folder == \".DS_Store\" :\n                plant_disease_folder_list.remove(disease_folder)\n\n        for plant_disease_folder in plant_disease_folder_list:\n            print(f\"[INFO] Processing {plant_disease_folder} ...\")\n            plant_disease_image_list = listdir(f\"{directory_root}/{plant_folder}/{plant_disease_folder}/\")\n                \n            for single_plant_disease_image in plant_disease_image_list :\n                if single_plant_disease_image == \".DS_Store\" :\n                    plant_disease_image_list.remove(single_plant_disease_image)\n\n            for image in plant_disease_image_list[:200]:\n                image_directory = f\"{directory_root}/{plant_folder}/{plant_disease_folder}/{image}\"\n                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n                    image_list.append(convertImageToArray(image_directory))\n                    label_list.append(plant_disease_folder)\n    print(\"[INFO] Image loading completed\")  \nexcept Exception as e:\n    print(f\"Error : {e}\")\n\nimage_size = len(image_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T23:31:38.761125Z","iopub.execute_input":"2024-12-10T23:31:38.761495Z","iopub.status.idle":"2024-12-10T23:31:42.817890Z","shell.execute_reply.started":"2024-12-10T23:31:38.761461Z","shell.execute_reply":"2024-12-10T23:31:42.816997Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_binarizer = LabelBinarizer()\nimage_labels = label_binarizer.fit_transform(label_list)\npickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))\nn_classes = len(label_binarizer.classes_)\n\nprint(label_binarizer.classes_)\n\nnp_image_list = np.array(image_list, dtype=np.float16) / 225.0\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T23:19:10.665381Z","iopub.execute_input":"2024-12-10T23:19:10.665767Z","iopub.status.idle":"2024-12-10T23:19:19.009231Z","shell.execute_reply.started":"2024-12-10T23:19:10.665733Z","shell.execute_reply":"2024-12-10T23:19:19.008499Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"[INFO] Spliting data to train, test\")\nx_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state = 42) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T23:19:19.010654Z","iopub.execute_input":"2024-12-10T23:19:19.010913Z","iopub.status.idle":"2024-12-10T23:19:19.256690Z","shell.execute_reply.started":"2024-12-10T23:19:19.010887Z","shell.execute_reply":"2024-12-10T23:19:19.255969Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"aug = ImageDataGenerator(\n    rotation_range=30,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode=\"nearest\"\n)\n\n\ndef showImages(gen):\n    '''\n    This function takes the data generator and shows a sample of the images\n    '''\n    try:\n        # Get classes from label binarizer\n        classes = list(label_binarizer.classes_)\n        \n        # Prepare the generator\n        images, labels = next(gen.flow(x_train, y_train, batch_size=BS))\n        \n        # Calculate number of displayed samples\n        length = len(labels)\n        sample = min(length, 25)\n        \n        plt.figure(figsize=(20, 20))\n        for i in range(sample):\n            plt.subplot(5, 5, i + 1)\n            image = images[i]\n            plt.imshow(image)\n            \n            # Find the class index\n            index = np.argmax(labels[i])\n            class_name = classes[index]\n            \n            plt.title(class_name, color='blue', fontsize=12)\n            plt.axis('off')\n        plt.tight_layout()\n        plt.show()\n    except Exception as e:\n        print(f\"Error in showImages: {e}\")\n\nshowImages(aug)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T23:19:58.548494Z","iopub.execute_input":"2024-12-10T23:19:58.548882Z","iopub.status.idle":"2024-12-10T23:20:04.313022Z","shell.execute_reply.started":"2024-12-10T23:19:58.548852Z","shell.execute_reply":"2024-12-10T23:20:04.312060Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = Sequential()\ninputShape = (height, width, depth)\nchanDim = -1\nif K.image_data_format() == \"channels_first\":\n    inputShape = (depth, height, width)\n    chanDim = 1\nmodel.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(n_classes))\nmodel.add(Activation(\"softmax\"))\n\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T23:20:22.174448Z","iopub.execute_input":"2024-12-10T23:20:22.174832Z","iopub.status.idle":"2024-12-10T23:20:22.498255Z","shell.execute_reply.started":"2024-12-10T23:20:22.174798Z","shell.execute_reply":"2024-12-10T23:20:22.497412Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"opt = Adam(learning_rate=INIT_LR)\n# distribution\nmodel.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n# train the network\nprint(\"[INFO] training network...\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T23:20:27.554476Z","iopub.execute_input":"2024-12-10T23:20:27.555301Z","iopub.status.idle":"2024-12-10T23:20:27.564051Z","shell.execute_reply.started":"2024-12-10T23:20:27.555266Z","shell.execute_reply":"2024-12-10T23:20:27.563136Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.callbacks import EarlyStopping\nlr_scheduler = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6)\n\nearly_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n\n#This part can be run multiple times to increase training and val accuracy\nhistory = model.fit(\n    aug.flow(x_train, y_train, batch_size=BS),\n    validation_data=(x_test, y_test),\n    steps_per_epoch=len(x_train) // BS,\n    epochs=EPOCHS, verbose=1,callbacks=[early_stopping]\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T23:36:53.926284Z","iopub.execute_input":"2024-12-10T23:36:53.926654Z","iopub.status.idle":"2024-12-10T23:38:55.487064Z","shell.execute_reply.started":"2024-12-10T23:36:53.926620Z","shell.execute_reply":"2024-12-10T23:38:55.486357Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\n#Train and validation accuracy\nplt.plot(epochs, acc, 'b', label='Training accurarcy')\nplt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\nplt.title('Training and Validation accurarcy')\nplt.legend()\n\nplt.figure()\n#Train and validation loss\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and Validation loss')\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T23:36:41.246255Z","iopub.execute_input":"2024-12-10T23:36:41.246616Z","iopub.status.idle":"2024-12-10T23:36:42.160160Z","shell.execute_reply.started":"2024-12-10T23:36:41.246583Z","shell.execute_reply":"2024-12-10T23:36:42.159339Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"[INFO] Calculating model accuracy\")\nscores = model.evaluate(x_test, y_test)\nprint(f\"Test Accuracy: {scores[1]*100}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T23:39:09.581956Z","iopub.execute_input":"2024-12-10T23:39:09.582293Z","iopub.status.idle":"2024-12-10T23:39:12.160843Z","shell.execute_reply.started":"2024-12-10T23:39:09.582262Z","shell.execute_reply":"2024-12-10T23:39:12.159880Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# save the model to disk\nprint(\"[INFO] Saving model...\")\npickle.dump(model,open('cnn_model.pkl', 'wb'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T22:50:39.165318Z","iopub.execute_input":"2024-12-10T22:50:39.165693Z","iopub.status.idle":"2024-12-10T22:50:42.476283Z","shell.execute_reply.started":"2024-12-10T22:50:39.165660Z","shell.execute_reply":"2024-12-10T22:50:42.475573Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sqlite3\n\n# Create a connection to SQLite database\nconn = sqlite3.connect('plant_disease_data.db')\n\n# Create a table to store image metadata and labels\nconn.execute('''\n    CREATE TABLE IF NOT EXISTS image_metadata (\n        id INTEGER PRIMARY KEY,\n        plant_folder TEXT,\n        disease_folder TEXT,\n        image_path TEXT,\n        label TEXT\n    )\n''')\n\n# Function to insert image metadata\ndef insertImageData(plant_folder, disease_folder, image_path, label):\n    conn.execute('''\n        INSERT INTO image_metadata \n        (plant_folder, disease_folder, image_path, label) \n        VALUES (?, ?, ?, ?)\n    ''', (plant_folder, disease_folder, image_path, label))\n    conn.commit()\n\n# Modify your image loading code to also store metadata\nfor plant_folder in root_dir:\n    plant_disease_folder_list = listdir(f\"{directory_root}/{plant_folder}\")\n    plant_disease_folder_list = [d for d in plant_disease_folder_list if d != \".DS_Store\"]\n    \n    for disease_folder in plant_disease_folder_list:\n        plant_disease_image_list = listdir(f\"{directory_root}/{plant_folder}/{disease_folder}\")\n        plant_disease_image_list = [img for img in plant_disease_image_list if img != \".DS_Store\"]\n\n        for image in plant_disease_image_list[:200]:\n            image_directory = f\"{directory_root}/{plant_folder}/{disease_folder}/{image}\"\n            if image_directory.endswith((\".jpg\", \".JPG\")):\n                # Existing image processing\n                image_list.append(convertImageToArray(image_directory))\n                label_list.append(disease_folder)\n\n                # Store metadata in database\n                insertImageData(plant_folder, disease_folder, image_directory, disease_folder)\n\n\n# Close the connection when done","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T23:39:56.729224Z","iopub.execute_input":"2024-12-10T23:39:56.729573Z","iopub.status.idle":"2024-12-10T23:40:24.358645Z","shell.execute_reply.started":"2024-12-10T23:39:56.729540Z","shell.execute_reply":"2024-12-10T23:40:24.357712Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\ndef viewPandasDatabase():\n    # Read the entire table into a pandas DataFrame\n    df = pd.read_sql_query(\"SELECT * FROM image_metadata\", conn)\n    print(\"Database Contents:\")\n    print(df)\n    \n    # Additional useful information\n    print(\"\\nDatabase Summary:\")\n    print(f\"Total Records: {len(df)}\")\n    print(f\"Unique Plant Folders: {df['plant_folder'].nunique()}\")\n    print(f\"Unique Disease Folders: {df['disease_folder'].nunique()}\")\n\nviewPandasDatabase()\nconn.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T23:40:28.824869Z","iopub.execute_input":"2024-12-10T23:40:28.825198Z","iopub.status.idle":"2024-12-10T23:40:28.852878Z","shell.execute_reply.started":"2024-12-10T23:40:28.825168Z","shell.execute_reply":"2024-12-10T23:40:28.851995Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}